---
title: "Assignment02"
author: "Syed Muhammad Adeel Ibrahim"
date: "April 3, 2019"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question 1

1. This question works with a data set on sodium intake. We can read it into R with the
following code ...

```{r}
sodium <- read.table("sodium.txt", header=TRUE)

```

... and here are the first few rows of data ...

```{r}

head(sodium)
```

The Instructor is a nutrition advisor and Supplement is a nutritional supplement. Extract just the ???rst observation for each combination of Instructor and Supplement and create a matrix of the result.

```{r}

getObservation <- function (df){
  mat <- df
  matResult <- mat[1,]
  for(row in 1:nrow(mat)) {
    vec <- mat[row,]
    exist <- FALSE
    for (r in 1:nrow(matResult)) {
     if (
       vec["Instructor"][,1] == matResult [r,]["Instructor"][,1]
       & vec["Supplement"][,1] == matResult[r,]["Supplement"][,1]
     ) {
       exist <- TRUE
       break
     }
    }
    if (!exist) {
      matResult <- rbind(matResult, vec) 
    }
  }
  matResult
}

mat <- getObservation(sodium)

sodiumMat <- with(mat, {
  out <- matrix(
    nrow=nlevels(Instructor), 
    ncol=nlevels(Supplement),
    dimnames=list(Instructor= levels(Instructor), Supplement = levels(Supplement)))
  out[cbind(Instructor, Supplement)] <- Sodium
  out
})

sodiumMat

```

Use apply and sweep to ???t a model of the form ...
yij = ? + ??i + ??j + ij
... to these data.

Mean
```{r}
twoway <- function(y) { 
  mu <- mean(y) 
  y <- y - mu 
  alpha <- apply(y, 1, mean)
  y <- sweep(y, 1, alpha) 
  beta <- apply(y, 2, mean) 
  y <- sweep(y, 2, beta) 
  list(overall=mu, rows=alpha, cols=beta, residuals=y)
}

twoway(sodiumMat)
```

##Question 2

This question works with a set of plant weights, measured under two experimental conditions.

```{r}
## Annette Dobson (1990) "An Introduction to Generalized Linear Models". 
## Page 9: Plant Weight Data. 
## Control = standard conditions 
## Treatment = nutrient rich 
ctl <- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14)
trt <- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
group <- gl(2, 10, 20, labels = c("Ctl","Trt"))
weight <- c(ctl, trt)

(sigma <- sd(weight))

```

We are going to estimate the mean, ?, for the plant weights using Maximum Likelihood. The likelihood function is 

n Y i=1
f(xi;?)

where f(xi;?) is the Normal probability density function
1 / ???2????2e???(x????)2 2??2
Write an R function called like that calculates this likelihood, given a set of data x and a mean mu (Hint: the R function dnorm evaluates the Normal probability density given x, mu, and sigma).

```{r}

 like <- function(x, mu) {
  den <- dnorm(x, mu, sd(x))
  prod(den)
 }

like(weight, 0)

like(weight, 4)

```
```{r}

like <- function(x, mu) {
  den <- dnorm(x, mu, sd(x))
  plot(x, den, type="h", xlab = "weight", ylab = "density", main = bquote(mu == .(mu)))
  prod(den)
 }

like(weight, 0)

like(weight, 4)

```

```{r}
like <- function(x, mu) {
  likelihood <- 0
  counter <- 1
  for (m in mu) {
    den <- dnorm(x, m, sd(x))
    likelihood[counter] <- prod(den)
    counter <- counter + 1
  }
  plot(mu, likelihood, type="l", xlab = bquote(mu), ylab = "likelihood")
 }

like(weight, seq(0, 6, .01))
```

The log-likelihood is
n X i=1
log(f(xi;?))
Write a function loglike to calculate the log-likelihood (Hint: the dnorm function has an argument log).

```{r}

loglike <- function(x, mu) {
  den <- dnorm(x, mu, sd(x), log = TRUE)
  plot(x, den, type="h", xlab = "weight", ylab = "density", main = bquote(mu == .(mu)))
  sum(den)
 }

loglike(weight, 0)

loglike(weight, 4)

```

Plot log probability densities for the weight data given ? = 0 and ? = 4 and plot the log-likelihood curve for ? between 0 and 6.

```{r}
logLike <- function(x, mu) {
  likelihood <- 0
  counter <- 1
  for (m in mu) {
    likelihood[counter] <- sum(dnorm(x, m, sd(x), log = TRUE))
    counter <- counter + 1
  }
  plot(mu, likelihood, type="l", xlab = bquote(mu), ylab = "likelihood")
 }

logLike(weight, seq(0, 6, .01))
```

Use the optimise function to ???nd the maximum likelihood estimate of ? (???nd the value of ? that maximises the log-likelihood function).

```{r}

likelihood <- 0
counter <- 1

mu <- seq(0, 6, .01)

for (m in mu) {
  likelihood[counter] <- sum(dnorm(weight, m, sd(weight), log = TRUE))
  counter <- counter + 1
}

ll <- function(theta) { 
  sum(dnorm(weight, theta[1], theta[2], log=TRUE))
}

maxMu <- mu[which.max(likelihood)]

z <- optim(c(maxMu, sd(weight)), ll, control = list(fnscale=-1))

muMLE <- z$par[1]
muMLE
```
This should equal the sample mean

```{r}

mean(weight)

```

NOTE: using maximum likelihood estimation is NOT how we would normally estimate this parameter (or the parameters in the next two questions), but it can be a useful exercise to help understand how maximum likelihood works.

The ???rst derivative of the log-likelihood function (w.r.t. ?, assuming ?? known constant, and data x ???xed) is 
  
  constant ??? n X i=1 xi ???? 

Write a function dllike that calculates this ???rst derivative and use uniroot to ???nd where this function is zero (a plot of the function is shown below). This should produce the same answer as above.

```{r}
dllike <- function (mu) {
  sd(weight) * sum(weight - mu)
}

z <- uniroot(dllike, lower=0, upper=6)
z$root

```

## Question 3

3. [10 marks] This question also works with the set of plant weights and we will still assume that all weights are i.i.d. Normal(?, ??). However, we will now estimate both ? and ?? using maximum likelihood. The log-likelihood function is now
      n X i=1
      log(f(xi;?,??))
Write a function loglike2 to evaluate the log-likelihood, plot probability densities values for the weight data for both ? = 0;?? = 1 and ? = 4,?? = 1, and plot the log-likelihood function for ? between 0 and 6, with ?? = 1 and with ?? = .5.

```{r}
loglike2 <- function(x, mean, sd) {
  fn <- dnorm(x, mean, sd, log = TRUE)
  plot(x, fn, type="h", xlab = "weight", ylab = "density", main = bquote(mu == .(mean) ~ "; " ~ sigma == .(sd)))
  sum(fn)
 }

loglike2(weight, 0, 1)

loglike2(weight, 4, 1)
```

```{r}
logLike2 <- function(x, mu, sigma) {
  likelihood <- 0
  counter <- 1
  for (m in mu) {
    likelihood[counter] <- sum(dnorm(x, m, sigma, log = TRUE))
    counter <- counter + 1
  }
  plot(mu, likelihood, type="l", xlab = bquote(mu), ylab = "likelihood", main= bquote(sigma == .(sigma)))
 }

logLike2(weight, seq(0, 6, .01), 1)

logLike2(weight, seq(0, 6, .01), .5)
```


```{r}
mu <- 0:6
sigma <- 1:10

ll2 <- function(theta1, theta2) {
  
  ## Recycle arguments 
  n = length(weight) 
  m = max(length(theta1), length(theta2)) 
  
  if(length(theta1) < m) 
    theta1 = rep(theta1, len=m) 
  
  if(length(theta2) < m) 
    theta2 = rep(theta2, len=m) 
  
  ## Vector calculation 
  ans = dnorm(
    rep(weight, m), 
    rep(theta1, each=n), 
    rep(theta2, each=n), 
    log=TRUE
  ) 
  
  dim(ans) = c(n, m) 
  
  colSums(ans)
}


z <- outer(mu, sigma, ll2)
i <- which(z == max(z), TRUE)

theta <- c(mu[i[1]], sigma[i[2]])

ll <- function(theta) { 
  sum(dnorm(weight, theta[1], theta[2], log=TRUE))
}

z <- suppressWarnings(optim(theta, ll, control = list(fnscale=-1), method="BFGS", hessian = TRUE))

muSigmaMLE <- z$par
muSigmaMLE
```

```{r}
mean(weight)

sd(weight)

sd(weight)*sqrt((length(weight) - 1)/length(weight))

```

## Question 4 

This question also works with the set of plant weights, but now we will allow there to be a separate mean for the treatment and control groups. The log-likelihood function now looks like this

n X i=1
log(f(xi;??0 + g?????1,??)

where g is 0 for control weights and 1 for treatment weights. Find the maximum likelihood estimates for ??0, ??1, and ??.

```{r}
loglike3 <- function (weight, gp, beta0, beta1, sigma) {
  mu <- beta0 + gp * beta1
  logDensity <- dnorm(weight, mu, sigma, log = TRUE)
  plot(weight, logDensity, type="h", xlab = "weight", ylab = "log density", main = bquote(beta ~ "0" == .(beta0) ~ "; " ~ beta ~ "1" == .(beta1) ~ "; " ~ sigma == .(sigma)))
  sum(logDensity)
}

gp <- as.numeric(group) - 1

loglike3(weight, gp, 0, 1, 1)

loglike3(weight, gp, 4, 1, 1)
```

```{r}
logLike3 <- function(x, gp, beta0, beta1, sigma) {
  likelihood <- 0
  counter <- 1
  for (b in beta0) {
    mu <- b + gp * beta1
    likelihood[counter] <- sum(dnorm(x, mu, sigma, log = TRUE))
    counter <- counter + 1
  }
  plot(beta0, likelihood, type="l", xlab = bquote(beta ~ "0"), ylab = "Log-Likelihood", main = bquote( beta ~ "1" == .(beta1) ~ "; " ~ sigma == .(sigma)))
}

gp <- as.numeric(group) - 1

logLike3(weight, gp, seq(0, 6, .01), 1, 1)

logLike3(weight, gp, seq(0, 6, .01), 0, 1)
```

```{r}

gp <- as.numeric(group) - 1
beta0 <- seq(0, 6, length.out = length(gp))
beta1 <- seq(0, 6, length.out = length(gp))
sigma <- seq(1, 10, length.out = length(gp))

ll3 <- function(theta1, theta2, theta3) {
   
  if(length(theta1) < length(gp)) {
     theta1 <- rep(theta1, len=length(gp))
  }
  
  if(length(theta1) < length(gp)) {
     theta1 <- rep(theta1, len=length(gp))
  }
  
  ## Recycle arguments 
  n = length(weight) 
  m = max(length(theta1), length(theta2)) 
  
  ## Vector calculation 
  ans = dnorm(
    rep(weight, m), 
    rep(theta1, each=n), 
    rep(theta2, each=n), 
    log=TRUE
  ) 
  
  dim(ans) = c(n, m) 
  
  colSums(ans)
}

mu <- numeric(length(gp))

for(i in 1:length(gp)) {
  mu[i] <- beta0[i] + gp[i] * beta1[i]
}

z <- outer(mu, sigma, ll3)
i <- which(z == max(z), TRUE)

theta <- c(beta0[i[1]], beta1[i[1]], sigma[i[2]])

ll <- function(theta) { 
  sum(dnorm(weight, theta[1] + gp * theta[2] , theta[3], log=TRUE))
}

z <- suppressWarnings(optim(theta, ll, control = list(fnscale=-1), method="BFGS", hessian = TRUE))

(params <- z$par)
```

```{r}

lm.D9 <- lm(weight ~ group)
coef(lm.D9)
```


